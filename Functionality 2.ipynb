{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define shortest_path function, using the Dijkstra’s Algorithm: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trees as t\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path(graph, s, t):\n",
    "    \n",
    "    if s == t:\n",
    "        return \"There is no path, source and target nodes are the same\", -1\n",
    "    \n",
    "    unvisited, shortest_path, predecessor = list(), dict(), dict()\n",
    "    \n",
    "    # We set the distances between the source node and all other nodes to infinity, except for the distance between source \n",
    "    # and itself, which we set to 0.\n",
    "    for node in graph.nodes():\n",
    "        shortest_path[node] = math.inf\n",
    "        unvisited.append(node)\n",
    "    shortest_path[s] = 0\n",
    "    \n",
    "    # We loop untile we visit all the nodes in the graph\n",
    "    while unvisited:\n",
    "        # We choose the node with the smallest value as the “current node”\n",
    "        current_node = None\n",
    "        for node in unvisited: \n",
    "            if current_node == None:\n",
    "                current_node = node\n",
    "            elif shortest_path[node] < shortest_path[current_node]:\n",
    "                current_node = node\n",
    "        # visit all the  neighbour of current_node. As we visit each neighbor, we update their tentative distance \n",
    "        # from the starting node\n",
    "        for neighbor in graph.neighbors(current_node):\n",
    "            value = shortest_path[current_node] + graph[current_node][neighbor]['weight']\n",
    "            if value < shortest_path[neighbor]:\n",
    "                shortest_path[neighbor] = value\n",
    "                predecessor[neighbor] = current_node\n",
    "        unvisited.remove(current_node)\n",
    "    \n",
    "    if t not in predecessor:\n",
    "        return \"Not possible, there is no path between target and source\", -1\n",
    "    # now we have to return the path using predecessor dictionary\n",
    "    last = t\n",
    "    path = list([last])\n",
    "    while last != s:\n",
    "        path.append(predecessor[last])\n",
    "        last = predecessor[last]\n",
    "        \n",
    "    return path, shortest_path[t]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness centrality\n",
    "Let $n_{s,t}^{i}$ be the number of shortest paths from $s$ to $t$ that pass through $i$ and let $n_{s,t}$ be the total number of shortest paths from $s$ to $t$. Then the betweenness centrality of vertex $i$ is:\n",
    "\n",
    "$\\displaystyle{b_i = \\sum_{s, t} \\frac{n_{s,t}^{i}}{n_{s,t}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenness(v, graph):\n",
    "    num, den = 0, 0\n",
    "    #for each node we compute the shortest path with all the other nodes in the graph\n",
    "    for source in tqdm(graph.nodes()):\n",
    "        for target in graph.nodes():\n",
    "            if source != target and source != v and target != v:\n",
    "                path, dist = shortest_path(graph, source, target)\n",
    "                # if exist a shortest path between the source and the target, we update the denominator\n",
    "                if dist != -1:\n",
    "                    den += 1\n",
    "                    # if the node in input is in the shortest path then we update the numerator\n",
    "                    if v in path:\n",
    "                        num += 1\n",
    "    # we change the value of the denominator if it's equal to 0, to avoid dividing by zero                   \n",
    "    if den == 0:\n",
    "        den = 1\n",
    "    betweenness_centrality = num/den\n",
    "    return betweenness_centrality          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closeness centrality\n",
    "$C(v)={\\frac  {N-1}{\\sum _{u}d(u,v)}}$\n",
    "- N is the number of total nodes in the graph\n",
    "- $d(u,v)$ is the distance between the nodes u and v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeness(v, graph):\n",
    "    N = len(list(graph.nodes()))\n",
    "    count = 0\n",
    "    # for each node in the graph we calculate the distance between this node and the node in input\n",
    "    for node in tqdm(graph.nodes()):\n",
    "        path, dist = shortest_path(graph, v, node)\n",
    "        # if exist a path between the node in input v and \"node\" then we update the count of the distances \n",
    "        if dist != -1:\n",
    "            count += dist\n",
    "    if count == 0:\n",
    "        return \"There is no path between the node in input and all other nodes in the graph!\"\n",
    "    \n",
    "    closeness_centrality = (N - 1) / count\n",
    "    return closeness_centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree Centrality\n",
    "\n",
    "$D(v)={\\frac  {degree(v)}{N-1}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_centrality(v, graph):\n",
    "    N = len(list(graph.nodes()))\n",
    "    out_degree = 0\n",
    "    in_degree = 0\n",
    "    for (i,j) in graph.edges():\n",
    "        # for each edge in the graph we collect the number of outgoing edges from v\n",
    "        if i == v:\n",
    "            out_degree += 1\n",
    "        # for each edge in the graph we collect the number of ingoing edges in v\n",
    "        if j == v:\n",
    "            in_degree += 1\n",
    "    # the degree of a node is given by the sum of the in-degree and out-degree of the node\n",
    "    degree = in_degree + out_degree\n",
    "    degree_centrality = degree / (N-1)\n",
    "    return degree_centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page rank\n",
    "First we create the matrix P using this formula:\n",
    "<p>$P={\\frac{\\alpha}{N} * M + (1-\\alpha)*P_{rw}}$<p>\n",
    "<p> - $N$ is the number of nodes in the graph<p>\n",
    "<p> - $M$ is a matrix $N*N$ with all components equal to 1<p>\n",
    "<p> - $P_{rw}$ is a matrix $N*N$ in which the components are equal to 0, except for the components $a_{i,j}$ for which exist an edge between the node relative to $i$ row and the node relative to $j$ column, for these components the value is given by the normalized weight of the edge<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix_P(graph, alpha):\n",
    "    \n",
    "    N = len(list(graph.nodes()))\n",
    "    # to make the graph stochastic\n",
    "    graph = nx.stochastic_graph(graph, weight='weight')\n",
    "    \n",
    "    # initialize P_rw and M matrix\n",
    "    P_rw = np.zeros([N,N])\n",
    "    M = np.ones([N,N])\n",
    "    \n",
    "    # for each node in the graph, we define and memorize its position number in order to build the P_rw matrix\n",
    "    pos = dict()\n",
    "    count_pos = 0\n",
    "    for node in graph.nodes():\n",
    "        pos[node] = count_pos\n",
    "        count_pos += 1\n",
    "    \n",
    "    # for each node we see the edges that exit from this node\n",
    "    for node in pos:\n",
    "        col = list()\n",
    "        for (i,j) in graph.edges():\n",
    "        # for each node we collect the node in which each edge goes\n",
    "            if node == i:\n",
    "                col.append(j)\n",
    "        # then we update the component relative to \"node\" and \"elem\" of the P_rw matrix \n",
    "        for elem in col:\n",
    "            P_rw[pos[node]][pos[elem]] = graph[node][elem][\"weight\"]\n",
    "            \n",
    "   # finally we build the matrix P\n",
    "    P = ((alpha / N) * M) + ((1 - alpha) * P_rw)\n",
    "\n",
    "    return P, pos    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we compute the pagerank algorithm:\n",
    "- We start from select at random a starting node;\n",
    "- Then we initialize the $q_0$ vector, such that all of his components are equal to 0, except for the component relative to the starting node, which is equal to 1;\n",
    "- for each step $t$ of the algorithm we compute: $q_{t} = q_{t-1} * P$ and we check if the algorithm converges;\n",
    "- if the algorithm have converged we return the number of iterations needed and the page rank value relative to the node $v$ in input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank_score(v, graph, alpha, max_iter, tol):\n",
    "    \n",
    "    N = len(list(graph.nodes()))\n",
    "    P, pos = create_matrix_P(graph, alpha)\n",
    "    \n",
    "    # picking the start position at random\n",
    "    random.seed(123)\n",
    "    start_pos = random.randint(0, N)\n",
    "    \n",
    "    # find the position of the node in input using pos dictionary, we will use this position after when returning the pr\n",
    "    for key, value in pos.items():\n",
    "        if key == v:\n",
    "            input_node_pos = value\n",
    "    \n",
    "    # initialize the vector q such that there are all zeros except a one in the start_position\n",
    "    q_start = np.zeros(N)\n",
    "    q_start[start_pos] = 1\n",
    "    \n",
    "    #keep track of the convergence of the algorithm\n",
    "    convergence = False\n",
    "    \n",
    "    for step in tqdm(range(max_iter)):\n",
    "        # for every step we compute q_t = q_(t-1) * P\n",
    "        q_t = np.dot(q_start, P)\n",
    "        # calculate the error in order to check the convergence\n",
    "        err = sum([abs(q_t[i] - q_start[i]) for i in range(len(q_t))])\n",
    "        if err < N * tol:\n",
    "            print(\"the algorithm Page rank converges in \", step, \"iterations\")\n",
    "            return q_t[input_node_pos]\n",
    "        # update the vector q_start \n",
    "        q_start = q_t\n",
    "        \n",
    "    if convergence == False:\n",
    "        print(\"The algorithm did not converge for \", max_iter, \"number of iterations\")\n",
    "    \n",
    "    return q_t[input_node_pos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the functionality 2 that takes in input <p>\n",
    "<p> - A user/node <p>\n",
    "<p> - An interval of time <p>\n",
    "<p> - One of the following metrics: Betweeness 1, PageRank, ClosenessCentrality 3, DegreeCentrality <p>\n",
    "The output is the value of the given metric applied over the complete graph for the given interval of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionality_2(v, start_interval, end_interval, metric, alpha=None, max_iter=None, tol = None):\n",
    "    graph = t.build(\"a\", start_interval, end_interval)\n",
    "    if metric == \"Betweeness\":\n",
    "        return betweenness(v, graph)\n",
    "    elif metric == \"PageRank\" and alpha != None and max_iter != None and tol != None:\n",
    "        return pagerank_score(v, graph, alpha, max_iter, tol)\n",
    "    elif metric == \"ClosenessCentrality\":\n",
    "        return closeness(v, graph)\n",
    "    elif metric == \"DegreeCentrality\":\n",
    "        return degree_centrality(v, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████                                              | 22/50 [00:04<00:05,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the algorithm Page rank converges in  22 iterations\n",
      "1.6309058051812766e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(functionality_2(5730934, \"2016-01-01\", \"2016-01-03\", \"PageRank\", alpha=0.85, max_iter=50, tol = 0.000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00011669973159061734\n"
     ]
    }
   ],
   "source": [
    "print(functionality_2(5730934, '2016-01-01', '2016-01-07', \"DegreeCentrality\", alpha=None, max_iter=None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
